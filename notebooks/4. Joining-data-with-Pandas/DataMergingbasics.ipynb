{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d2fa76",
   "metadata": {},
   "source": [
    "# Data Merging Basics\n",
    "## Inner Join\n",
    "- Joining is basically merging different tables.\n",
    "- Merge method is used for inner joining.\n",
    "- Inner joins only return rows where matching values exist in both tables.\n",
    "- If a value is missing in one table, it will not appear in the merged result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f1d2faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "departments_facilities table shape: (50, 9)\n",
      "   department_id         department_name   head_of_department  \\\n",
      "0              1        Computer Science      Dr. Alan Turing   \n",
      "1              2  Mechanical Engineering     Dr. Nikola Tesla   \n",
      "2              3       Civil Engineering  Dr. Isambard Brunel   \n",
      "3              4  Electrical Engineering    Dr. Thomas Edison   \n",
      "\n",
      "            building phone_number  \n",
      "0  Engineering Block     555-1001  \n",
      "1          Tech Park     555-1002  \n",
      "2        Main Campus     555-1003  \n",
      "3   Innovation Tower     555-1004  \n",
      "   department_id library_available laboratory_available sports_facility  \\\n",
      "0              1               Yes                  Yes              No   \n",
      "1              2               Yes                  Yes             Yes   \n",
      "2              3               Yes                  Yes              No   \n",
      "3              4               Yes                  Yes             Yes   \n",
      "\n",
      "  parking_space  \n",
      "0       Limited  \n",
      "1      Adequate  \n",
      "2       Limited  \n",
      "3      Adequate  \n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "departments = pd.read_csv(r\"C:\\Users\\Dell\\OneDrive\\Desktop\\KaranCodes\\Datacampcourses\\Associate-Data-Scientist-Python-Track\\resources\\joiningdatawithpandas\\university_departments.csv\")\n",
    "facilities = pd.read_csv(r\"C:\\Users\\Dell\\OneDrive\\Desktop\\KaranCodes\\Datacampcourses\\Associate-Data-Scientist-Python-Track\\resources\\joiningdatawithpandas\\department_facilities.csv\")\n",
    "\n",
    "# Merge the departments and facilities tables on the dept_id column\n",
    "departments_facilities = departments.merge(facilities, on='department_id', suffixes=('_dept', '_fac'))\n",
    "\n",
    "# Print the shape of departments_facilities\n",
    "print('departments_facilities table shape:', departments_facilities.shape)\n",
    "\n",
    "# Print the original tables\n",
    "print(departments.head(4))\n",
    "print(facilities.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f49a1",
   "metadata": {},
   "source": [
    "## One to many relationships\n",
    "- In a one-to-many merge, a single row in the left table can match multiple rows in the right table.\n",
    "- During the merge:\n",
    "  - The left tableâ€™s row is repeated for each matching row in the right table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a1ed47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       account\n",
      "zip           \n",
      "60619        3\n",
      "60607        2\n",
      "60605        2\n",
      "60608        2\n",
      "60632        2\n"
     ]
    }
   ],
   "source": [
    "# Load the business_owners and store_locations data\n",
    "business_owners = pd.read_csv(r\"C:\\Users\\Dell\\OneDrive\\Desktop\\KaranCodes\\Datacampcourses\\Associate-Data-Scientist-Python-Track\\resources\\joiningdatawithpandas\\business_owners.csv\")\n",
    "store_locations = pd.read_csv(r\"C:\\Users\\Dell\\OneDrive\\Desktop\\KaranCodes\\Datacampcourses\\Associate-Data-Scientist-Python-Track\\resources\\joiningdatawithpandas\\store_locations.csv\")\n",
    "\n",
    "# Merge the datasets on 'account'\n",
    "business_details = business_owners.merge(store_locations, on='account')\n",
    "\n",
    "# Group by 'zip' and count the number of businesses\n",
    "zip_count = business_details.groupby(\"zip\").agg({'account': 'count'})\n",
    "\n",
    "# Sort the results in descending order\n",
    "sorted_zip = zip_count.sort_values(\"account\", ascending=False)\n",
    "\n",
    "# Print the sorted dataframe\n",
    "print(sorted_zip.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d3e7a2",
   "metadata": {},
   "source": [
    "## Merging multiple tables\n",
    "- df1.merge(df2, on='col') \\ .merge(df3, on='col') \\ .merge(df4, on='col')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8b7fdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1880\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "deliveries = pd.read_csv(r\"C:\\Users\\Dell\\OneDrive\\Desktop\\KaranCodes\\Datacampcourses\\Associate-Data-Scientist-Python-Track\\resources\\joiningdatawithpandas\\deliveries.csv\")\n",
    "calendar = pd.read_csv(r\"C:\\Users\\Dell\\OneDrive\\Desktop\\KaranCodes\\Datacampcourses\\Associate-Data-Scientist-Python-Track\\resources\\joiningdatawithpandas\\calendar.csv\")\n",
    "hubs = pd.read_csv(r\"C:\\Users\\Dell\\OneDrive\\Desktop\\KaranCodes\\Datacampcourses\\Associate-Data-Scientist-Python-Track\\resources\\joiningdatawithpandas\\hubs.csv\")\n",
    "\n",
    "# Merge the deliveries, calendar, and hubs tables\n",
    "deliveries_full = deliveries.merge(calendar, on=['year', 'month', 'day']) \\\n",
    "                            .merge(hubs, on='hub_id')\n",
    "\n",
    "# Create the filter\n",
    "filter_criteria = ((deliveries_full['month'] == 7) &\n",
    "                   (deliveries_full['day_type'] == 'Weekday') &\n",
    "                   (deliveries_full['hub_name'] == 'Central Hub'))\n",
    "\n",
    "# Apply the filter and sum packages delivered\n",
    "total_packages = deliveries_full.loc[filter_criteria, 'packages_delivered'].sum()\n",
    "\n",
    "# Print the result\n",
    "print(total_packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90746d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    hub_id open_status delivery_type  delivery_id\n",
      "5      102        Open       Express            1\n",
      "7      102        Open      Standard            1\n",
      "11     103        Open      Standard            1\n",
      "2      101        Open       Express            2\n",
      "9      103        Open       Express            2\n"
     ]
    }
   ],
   "source": [
    "# Merge deliveries and calendars on year, month, day\n",
    "# Then merge result with hubs on hub_id with suffixes\n",
    "deliveries_cal_hubs = deliveries.merge(calendar, on=['year', 'month', 'day']) \\\n",
    "                                .merge(hubs, on='hub_id', suffixes=('_cal', '_hub'))\n",
    "\n",
    "# Group by hub_id, open_status, and delivery_type, then count number of deliveries\n",
    "grouped_deliveries = deliveries_cal_hubs.groupby(['hub_id', 'open_status', 'delivery_type'], \n",
    "                                                  as_index=False).agg({'delivery_id':'count'})\n",
    "\n",
    "# Sort by open_status, delivery_id, and hub_id\n",
    "sorted_grouped_deliveries = grouped_deliveries.sort_values([\"open_status\", 'delivery_id', 'hub_id'], \n",
    "                                                           ascending=[False, True, True])\n",
    "\n",
    "# Print the top few rows\n",
    "print(sorted_grouped_deliveries.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ec85b",
   "metadata": {},
   "source": [
    "## Left Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c6c6cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "books_info = pd.read_csv(r\"C:\\Users\\Dell\\OneDrive\\Desktop\\KaranCodes\\Datacampcourses\\Associate-Data-Scientist-Python-Track\\resources\\joiningdatawithpandas\\books_info.csv\")\n",
    "books_sales = pd.read_csv(r\"C:\\Users\\Dell\\OneDrive\\Desktop\\KaranCodes\\Datacampcourses\\Associate-Data-Scientist-Python-Track\\resources\\joiningdatawithpandas\\books_sales.csv\")\n",
    "\n",
    "# Merge the books_info table with the books_sales table using a left join\n",
    "books_full = books_info.merge(books_sales, on='id', how='left')\n",
    "\n",
    "# Count the number of rows in the budget column (revenue) that are missing\n",
    "number_of_missing_sales = books_full['revenue'].isna().sum()\n",
    "\n",
    "# Print the number of books missing sales data\n",
    "print(number_of_missing_sales)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5879514d",
   "metadata": {},
   "source": [
    "### Enriching a dataset using left join\n",
    "- Left joins (using how='left' in .merge()) are great for enriching datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4464a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Revenue of Books: 1995000.0\n"
     ]
    }
   ],
   "source": [
    "# Perform a left join to merge books_info and books_sales\n",
    "books_merged = books_info.merge(books_sales, on='id', how='left')\n",
    "\n",
    "# Fill missing revenue values with 0 (assuming no sales were made)\n",
    "books_merged['revenue'] = books_merged['revenue'].fillna(0)\n",
    "\n",
    "# Calculate and print the average revenue for all books\n",
    "average_revenue = books_merged['revenue'].mean()\n",
    "print(f\"Average Revenue of Books: {average_revenue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b9db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
